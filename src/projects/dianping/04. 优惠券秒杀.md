---
title: 04. 优惠券秒杀
article: false
category:
  - 项目
  - 《优享生活圈》
tag:
  - 防超卖
  - 一人一单
  - Kafka
date: 2026-02-15
---
## 一、秒杀防超卖和一人一单
+ **秒杀防超卖和一人一单**：使用 Redis 存储库存和订单信息，Lua 判断用户下单资格，保证库存不超卖和一人一单；

### 1.1 问题解决
:::info 背景
平台上商家可以发布一些折扣力度很大的优惠券，这种优惠券是某个时间点限量供应的，所以在这个时间点会有比较大的流量进入，也就是一个秒杀场景，必须要保证的是在高并发的情况下，防止库存超卖，以及这种优惠券是限制每位用户只能购买一次。即防库存超卖和一人一单。

要达到目的，只需要做好校验，校验用户是否有资格下单，如果库存不足或者用户已经下过单，则此时可认为用户是没有资格下单，拒绝请求。反之用户有资格下单则进行后续流程。

:::

那我们如何做这个校验呢？首先很容易想到的方案是：

+ 针对一人一单，去数据库查用户是否已经下过单，如果查到用户对应优惠券的订单，说明已经下过单，则拒绝请求。这个过程中为了防止<font style="color:rgb(222,120,2);">同一个用户</font>发起多个下单请求，还需要使用<font style="color:rgb(216,57,49);">分布式锁</font>保证并发安全。
+ 针对库存是否超卖，只需要在减库存时，即 update 库存的时候应该加上 where 库存 > 0 , 自然不会超卖。

:::warning 注意
<font style="color:rgb(216,57,49);">但是</font>在高并发的情况下，大量的请求 查询数据库和尝试更新数据（update是需要给记录加锁的，存在锁竞争），并且还使用了分布式锁，使得整个秒杀业务的性能受到很大影响。

使用 JMeter 测试 QPS 1000，200个库存的情况下，平均响应时间是500ms，比较慢。

:::

**因此需要进行优化，**

第一，我不想因为 <font style="color:rgb(222,120,2);">下单资格的判断</font> 让MySQL数据库去承载高并发的查询和更新，那我觉得可以在Redis中完成用户下单资格的判断。 

第二，既然使用了Redis，那么我联想到 Lua 正好是原子性的，可以解决一人一单的并发安全问题，也就不再需要使用<font style="color:rgb(222,120,2);">分布式锁</font>。

也就是说我可以<font style="background-color:#FBDE28;">把下单资格的判断 （防止库存超卖和一人一单） 在Redis的Lua脚本中</font>完成

那么前提呢？就需要把 优惠券 <font style="color:rgb(222,120,2);">库存信息和订单信息</font> 存储Redis里

+ 存储在Redis的优惠券<font style="color:rgb(216,57,49);">库存信息</font>包括： 优惠券的库存、优惠券开始秒杀时间和结束秒杀时间
    - `使用 <font style="background-color:#81DFE4;">String</font> 即可，key：业务前缀+优惠券的ID value：优惠券库存信息`
    - 当想要校验库存是否充足时，只需要判断Redis中的库存是否大于0，
    - 同时 当已判断用户有下单资格后，下单成功，<font style="color:rgb(222,120,2);">在Redis中预减库存</font>
    - 这样，只要Redis的库存减到0，后续的请求都会被拒绝，库存一定不会超卖（<font style="color:rgb(222,120,2);">Redis单线程执行</font>）
+ 存储在Redis的<font style="color:rgb(216,57,49);">订单信息</font>：其实只需要记录 优惠券被哪些用户购买过
    - `使用 <font style="background-color:#81DFE4;">Set</font> 数据类型即可，key是：业务前缀+优惠券的ID value是：所有购买过该优惠券的用户ID`
    - 当想要校验一人一单时，只需要判断对应优惠券key的value中是否已有该用户ID（SISMEMBER），如果已有说明购买过，拒绝请求
    - 同时，当判断用户有下单资格后，下单成功，也需要将该用户ID记录到该key的集合中。

<font style="color:#DF2A3F;">修改后</font>：JMeter 测试 QPS 1000，200个库存，平均响应时间是176ms，性能提高64.8%

### 1.2 衍生思考
#### （1）_**如果是一人两单或一人N单呢？用Set还能做到吗？**_
Set 数据类型 只能记录用户 "是否购买过"，无法记录 "购买了几次"。因此可以使用 Hash

每个优惠券创建一个Hash结构<font style="color:rgb(216,57,49);"> {优惠券ID，（用户ID，单量）}</font>

+ Key 是：业务前缀+优惠券的ID 
+ Field：用户ID 作为字段名
+ Value：该用户对该优惠券的当前已购买数量（甚至可以扩展，也记录下订单号、支付状态）

此时只需要校验Value用户购买的数量即可完成一人N单的需求

#### （2）_**如果某个券允许购买的用户量很大，用Set或Hash存储该券的订单数据，会不会造成大Key？**_
**答：**大Key是指 Value体积过大（如String类型 > 2MB，Hash/List元素>5000个）的Key

从业务上来讲，一般情况下，

一次秒杀活动中，针对单个优惠券，不会提供大量的库存，即存在大Key的可能性较小

但如果真的有某个券的库存很多，导致产生大Key，解决的方案是<font style="color:rgb(222,120,2);">拆分大key为多个小key</font>。

按<font style="background-color:#81DFE4;">时间或商品ID</font>拆分大 Key：避免将所有库存和购买记录都存储在一个 Redis Key 中。

**Redis 集群**：如果单一Redis 实例无法承载大量数据，可以使用 Redis Cluster 进行水平扩展。

**过期策略**：为 Redis 中的数据设置<font style="color:rgb(222,120,2);">合理的过期时间</font>，避免过期数据积压。

## 二、秒杀流程优化
### 2.1 问题解决
:::info 背景
平台上商家可以发布一些折扣力度很大的优惠券，这种优惠券是某个时间点限量供应的，所以在这个时间点会有比较大的流量进入，也就是一个秒杀场景，在判断完毕用户有资格下单后，就会扣减MySQL的库存、生成订单。

在秒杀这个高并发的场景下，扣减库存、生成订单，其实是两次MySQL数据库操作，使得整个秒杀业务的性能受到很大影响。

:::

之前是一个同步流程，<font style="color:rgb(216,57,49);">判断资格-->扣减库存-->生成订单</font>。

<font style="color:rgb(216,57,49);">其实在redis层，判断完用户有资格下单 (库存不超卖、一人一单) 后，就意味着用户下单成功、秒杀成功</font>

<font style="color:rgb(216,57,49);">至于MySQL的库存扣减和订单生成，完全可以</font><font style="color:rgb(216,57,49);background-color:#81DFE4;">异步</font><font style="color:rgb(216,57,49);">的来做</font>。

我们可以在判断用户有下单资格后，发送一个<font style="background-color:#81DFE4;">Kafka</font>消息，另外启动一个Kafka消费者监听消息，在消费者的逻辑内去扣减库存、生成订单。通过`<font style="color:rgb(216,57,49);">同步变异步</font>`，提高秒杀场景的并发性能。

并且，<font style="color:rgb(216,57,49);">如果以后业务有所扩展</font>，例如用户下单成功后，需要 额外的做一些事情(例如通知用户下单成功)，也可以放到Kafka消费者里去做，而不是不断的新增在秒杀的同步流程中。

### 2.2 衍生思考
#### （1）_**避免重复消费**_
**<font style="background-color:rgb(246,241,254);">幂等性</font>**<font style="background-color:rgb(246,241,254);">（Idempotence）这个概念其实很简单，它指的是“</font>**<font style="background-color:rgb(246,241,254);">无论你做多少次相同的操作，结果都是一样的</font>**<font style="background-color:rgb(246,241,254);">”。</font>

启用 Kafka <font style="background-color:#81DFE4;">生产者</font>幂等性

Kafka 生产者可以通过启用幂等性来避免消息重复发送：

当生产者发送消息时，Kafka 会为每条消息分配一个 **唯一的序列号**。当消息被重试时，Kafka 会通过消息的序列号来判断是否是重复的。如果消息的序列号较小（即是一个已处理过的消息），Kafka 会丢弃该消息，避免重复消费。

**<font style="background-color:#81DFE4;">消费者</font>**端实现幂等性/去重

Kafka 本身是<font style="color:#DF2A3F;"> at-least-once </font>语义，因此消费者必须保证幂等。我采用数据库唯一索引保证幂等性。在生成订单时提前生成全局唯一 orderId，并在订单表对 orderId 建立唯一索引。消费时直接 insert，如果成功说明首次消费；如果触发唯一索引异常，我会捕获异常并认为是幂等命中，直接 ack，从而保证重复消费不会影响系统状态。这种方式简单可靠，是生产环境中最常见的做法。

:::warning 注意
如果业务量极大，考虑使用 Redis 做第一层幂等过滤，数据库唯一索引做最终兜底，形成“双层幂等保护”。

:::

#### （2）_**Kafka怎么保证消息不丢失的？**_
**<font style="background-color:#81DFE4;">生产者</font>**：发送消息不丢失

**回调机制（Callback）**：生产者通过<font style="color:rgb(216,57,49);">带回调方法的 API </font>发送消息，回调函数会告知消息是否成功发送。如果消息发送失败，生产者可以在回调中进行异常处理。例如，可以将失败的消息存储到本地磁盘或远程数据库，以便后续重新发送。

`acks` 参数：`<font style="color:rgb(216,57,49);">acks=-1</font>` 表示消息必须在被写入到主副本（Leader）以及所有副本（Follower）后，才返回响应。这个设置确保即使某个副本宕机，消息仍然能够被保留。

`retries 参数：设置消息发送失败后的最大重试次数（例如，`retries=3`），通过自动重试确保在网络或 Broker 故障时尽量减少消息丢失的风险。

**<font style="background-color:#81DFE4;">Broker</font>**：保存消息不丢失

**副本机制**：Kafka 通过设置分区副本数（`replication.factor > 1`）来确保数据持久化。如果某个副本的 Leader 挂掉，其他副本会选举出新的 Leader，确保消息的可靠性和高可用性。

**日志存储**：Kafka 将所有消息按分区存储为日志文件，消息会追加写入磁盘直到被删除。Kafka 的这种<font style="color:rgb(216,57,49);">持久化机制</font>使得数据不会因为 Broker 重启或失败而丢失。

**<font style="background-color:#81DFE4;">消费者</font>**：确保不漏消费消息

Kafka 将每个 **Topic** 划分为多个 **Partition（分区）**，每个分区内的消息都是有序的。每条消息在分区内都会被分配一个唯一的 **offset**，从 `0` 开始递增。例如，第一个消息的 offset 为 `0`，第二个为 `1`，依此类推。

**手动提交 offset**：需要<font style="color:rgb(216,57,49);">禁用 自动提交消息偏移量 的机制</font>。因为在业务逻辑未完成时，可能会导致 offset 提交过早，导致消息丢失。手动提交 offset 可以确保只有在业务逻辑成功处理后，才更新消费进度，<font style="color:rgb(216,57,49);">避免漏消费</font>。

> **Offset** 在 Kafka 中指的是 **分区内消息的位移**，即某个消费者在 Kafka 分区中消费到的消息的位置。
>
> **一个业务过程可能会涉及多条消息，在这种情况下，正确的 offset 提交 就变得非常重要。**
>
> **Topic**：消息的主题或类别，相当于一个大的消息队列。
>
> **Partition**：是对 **Topic** 的划分，每个 **Partition** 都是一个独立的队列。Kafka 通过分区来提高并发处理和存储的能力。
>
> **消费者组（Consumer Group）** 是 Kafka 中的一个重要概念，它将多个消费者组织在一起，组成一个逻辑上的消费单元。
>
> **<font style="color:rgb(216,57,49);">一个分区</font>****在****<font style="color:rgb(216,57,49);">一个消费者组内</font>****只能由一个消费者来消费**，以**<font style="color:rgb(216,57,49);">确保每条消息只被消费一次</font>**。
>
> **一个消费者可以消费多个分区**，但 **每个分区只能由一个消费者消费**。
>
> 如果 **消费者数少于分区数**，一个消费者可能会消费多个分区。
>
> 如果 **消费者数多于分区数**，多余的消费者会处于空闲状态。
>

#### （3）_**Kafka消息堆积怎么办？**_
**<font style="background-color:#81DFE4;">消费者端优化</font>**

消费者**消费速度太慢**，导致消息积压，可以优化消费者代码逻辑当消费者数量少于partition分区数量时，可以**增加消费者数量**（但不能超过partition的数量）

**<font style="background-color:#81DFE4;">生产者端优化</font>**

**控制生产速度**：例如<font style="color:rgb(216,57,49);">在生产者端设置</font>**<font style="color:rgb(216,57,49);">限流机制</font>**，避免消息生产速度过快

**<font style="background-color:#81DFE4;">Kafka集群优化</font>**

**调整分区数量**：根据消息生产和消费速度，合理调整主题的分区数量。如果消息堆积是由于分区数过少导致，可增加分区数。例如，将一个原本只有2个分区的主题，根据业务量增加到10个分区，以**提高并行处理能力**。但分区数过多也会增加管理开销，需谨慎评估。

#### _**Redis库存扣减了，但是数据库的库存没有扣减、订单没有生成怎么办？**_
一人一单和库存不超卖，是由 Redis 存储库存和订单信息，使用 Lua 完成用户下单资格判断 来保证的。 <font style="background-color:#81DFE4;">秒杀的核心要求不受影响</font>。

如果消息丢失了，其实只是MySQL中的库存信息不正确、以及用户的订单记录没有及时生成。即数据一致性的问题。

此时完全可以设计一个<font style="color:rgb(216,57,49);">兜底策略</font>。设置一个在秒杀结束后执行的<font style="color:rgb(216,57,49);">定时任务，去检查Redis的库存信息和MySQL的库存信息是否一致，检查订单是否都正常生成。</font>如果有异常情况，即可修复。

> **其实就是一个对账的思想/策略**，也就是说上面其实可以不用Set存储购买过优惠券的用户ID，而是像前面说过的用Hash，这样在最后定时任务可以去<font style="color:rgb(216,57,49);">查Redis中的订单数据和MySQL中的订单数据</font>，进行比对验证。如果一致就没问题，如果不一致，那么可能是丢消息了或者系统执行异常了。可能需要人工介入排查。
>

#### （4）_**顺序消费的实现**_
**消息顺序消费指的是，多个消息需要按照先后顺序依次消费**

多个消息 如果写入同一个 Topic 的不同 partition 分区，由于不同 partition 分区消息被消费的速度是不可预知的，所以此时无法保证消息被顺序消费，

因此，多个消息，需要<font style="background-color:#81DFE4;">写入同一个 Topic 的 同一个 partition 分区</font>，至少在单个分区内，消息是有序的，同时，需要保证每个 partition 分区由一个消费者消费，确保 单个分区内的消息按顺序处理。

#### （5）_**使用Kafka的代码参考**_
```java
// 引入 KafkaTemplate, 类似于 RedisTemplate
@Autowired
private KafkaTemplate<String, Object> kafkaTemplate;

@Override
public Result seckillVoucher(Long voucherId) {
Long userId = UserHolder.getUser().getId();
// 1.执行lua脚本,判断是否有资格下单
Long result = stringRedisTemplate.execute(
    SECKILL_SCRIPT,
    Collections.emptyList(),
    voucherId.toString(),
    userId.toString()
);
if(result == 1){
    return Result.fail("库存不足");
}
if(result == 2){
    return Result.fail("重复下单");
}
// 有购买资格
long orderId = redisIdWorker.nextId("order");
VoucherOrder voucherOrder = new VoucherOrder();
voucherOrder.setId(orderId);    // 订单ID
voucherOrder.setUserId(userId); // 用户ID
voucherOrder.setVoucherId(voucherId); // 优惠券ID

// 生产Kafka消息
String topic = "指定的Topic";
ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, voucherOrder.toString());
// 回调函数
future.addCallback(
    new ListenableFutureCallback<SendResult<String, Object>>() {
        @Override
        public void onFailure(Throwable ex) {
            log.error("kafka sendMessage error, ex = {}, topic = {}, data = {}", ex, topic, voucherOrder);
        }

        @Override
        public void onSuccess(SendResult<String, Object> result) {
            log.info("kafka sendMessage success topic = {}, data = {}", topic, voucherOrder);
        }
    });
log.info("kafka sendMessage end");
return Result.ok(orderId);
}
```

```java
@Slf4j
@Component
public class SeckillVoucherConsumer {
    @KafkaListener(topics = "#{kafkaTopicName}")
    public void processMessage(ConsumerRecord<String, Object> record, Acknowledgment ack) {
        try {
            // 获取消息内的数据
            VoucherOrder order = (VoucherOrder) record.value();
            // 1. 生成订单... 操作数据库

            // 2. 扣减库存... 操作数据库

            ack.acknowledge(); // 仅业务成功时提交
        } catch (Exception e) {
            log.error("消费异常: topic={}, offset={}, 原因={}",
                      record.topic(), record.offset(), e.getMessage());
            // 不提交！等待重试或进入死信队列
        }
    }
}
```

## 三、Kafka技术细节
### 3.1 消息队列作用
MQ：MessageQueue，消息队列。 队列，是⼀种FIFO 先进先出的数据结构。消息则是跨进程传递的数据。 

⼀个典型的MQ系统，会将消息消息由⽣产者发送到MQ进⾏排队，然后根据⼀定的顺序交由消息的消费者进⾏ 

处理。 QQ和微信就是典型的MQ。只不过他对接的使⽤对象是⼈，⽽Kafka需要对接的使⽤对象是应⽤程序。 

<font style="color:rgb(216,57,49);">MQ的作⽤主要有以下三个⽅⾯：</font>

+ 异步：能提⾼系统的响应速度、吞吐量。 
+ 解耦：减少服务之间的影响，便于拓展。
+ 削峰：以稳定的系统资源应对突发的流量冲击。

### 3.2 kafka核心概念
:::info 重要组件
Kafka 包含若干 Producer、若干Broker、若干 Consumer 以及一个 Zookeeper 集群。

+ Zookeeper 是 Kafka 用来负责集群元数据管理、控制器选举等操作的。
+ Producer 是负责将消息发送到 Broker 的。
+ Broker 负责接受消息，将消息持久化到磁盘。
+ Consumer 是负责从 Broker 订阅并消费消息。

:::

<!-- 这是一张图片，ocr 内容为： -->
![](https://jiwang.cc.cd/PicGo/1771390788820-1639c971-bf54-421b-b845-69b6f6b371e2.png)

#### （1）Broker
+ 一个Kafka的集群通常由多个Broker组成，这样才能实现负载均衡、以及容错
+ Broker是**无状态（Sateless）**的，它们是通过ZooKeeper来维护集群状态
+ 一个Kafka的Broker每秒可以处理数十万次读写，每个Broker都可以处理TB消息而不影响性能

#### （2）Zookeeper
+ ZK用来管理和协调 Broker，并且存储了Kafka的元数据（例如：有多少topic、partition、consumer、producer）
+ ZK服务主要用于通知生产者和消费者Kafka集群中有新的Broker加入、或者Kafka集群中出现故障的Broker。

#### （3）Topic
<font style="color:rgb(216,57,49);">Kafka中Topic是一个逻辑概念</font>

+ 所谓发布订阅机制
    - 生产者发布的消息是需要指定一个Topic的，含义即这个消息属于这个“主题”Topic，也可以把“主题”理解为“类别”，生产者就会把消息发送到所指定的Topic。
    - 通常一个Topic中只会专门存储某一类的（消息）信息，比如 Topic（A）专门存储用户观看直播时长信息、Topic（B）专门存储直播PK开始信息。并且在一个Topic中的消息是有固定结构的。
    - 消费者是从它所指定订阅的 “主题”Topic 中去拉取的。
+ 一个主题Topic被分成多个Partition分区

#### （4）Partition
<!-- 这是一张图片，ocr 内容为： -->
![](https://jiwang.cc.cd/PicGo/1771390788866-5c6bfb41-4389-4065-b414-5e9a91480a4e.png)

一个主题Topic被分成多个Partition分区（Topic是逻辑概念，即无实体的）

+ Partition分区 是最小的存储单元，掌握着一个Topic的部分数据。
+ 每个 Partition 分区都是一个单独的 log 文件，每条记录都以追加的形式写入。
+ 一个 Topic 的所有 Partition分区 是分布在多个不同的Broker中的，所有 Partition 分区的数据的并集就是所有数据，提高容错率、提高消息的消费能力。
+ 一个 Partition 会生成多个副本Replica，并且把它们分散存储在不同的 Broker 中。在Kafka中，一般都会设计副本Replica的个数 > 1

#### （5）Offset
<font style="background-color:#81DFE4;">Offset 的定义</font>

Offset 是 Kafka 在分区内为每条消息分配的递增编号，<font style="background-color:rgba(255,246,122,0.8);">本质上是消息在日志文件中的物理位置</font>。它是单调递增且不可重用的，即使旧消息因过期被删除，新的消息仍然使用更大的 Offset。这种设计保证了消费者可以基于 Offset 精确地控制消费进度，并实现 at-least-once 语义。

<font style="background-color:#81DFE4;">Offset 的作用</font>

+ 定位消息。**通过指定 offset，消费者可以准确地找到分区中的某条消息，或者从某个位置开始消费消息**。
+ **记录消费进度**。消费者在消费完一条消息后，需要提交 offset 来告诉 Kafka broker 自己消费到哪里了。这样，如果消费者发生故障或重启，它可以根据保存的 offset 来恢复消费状态。

<font style="background-color:#81DFE4;">Offset 的存储</font>

+ 老版本默认Kafka将Offset存储在Zookeeper中
+ Kafka 0.9.0 版本后，offset 的实际存储位置都是在 Kafka 的一个内置主题中：consumer_offsets。这个主题有 50 个分区（可配置），每个分区存储一部分消费组（Consumer Group）的 offset 信息。Kafka broker 会根据消费组 ID 和主题名来计算出一个哈希值，并将其映射到 consumer_offsets 主题的某个分区上。

<font style="background-color:#81DFE4;">Offset 的提交与重置</font>

<font style="color:#DF2A3F;">提交 offset</font>

消费者在消费 Kafka 消息时，需要维护

+ 当前消费的 offset 值，表示消费者正在消费的消息的位置，
+ 已提交的 offset 值，表示消费者已经跟Kafka确认了已消费过的消息的位置。

消费者在消费完一条消息后，需要提交 offset 来更新已提交的 offset 值。

提交 offset 的方式有两种：自动提交和手动提交。

+ 自动提交：Kafka 提供了一个配置参数 enable.auto.commit，默认为 true，表示开启自动提交功能。**自动提交功能会在后台定期**（由 auto.commit.interval.ms 参数控制）**将当前消费的 offset 值提交给 Kafka broker。**
+ 手动提交：如果 enable.auto.commit 设置为 false，则表示关闭自动提交功能，此时**消费者需要手动调用 commitSync 或 commitAsync 方法来提交 offset。**手动提交功能可以让消费者更灵活地控制何时以及如何提交 offset。

:::warning 注意
需要注意的是，<font style="color:rgb(216,57,49);">无论是自动提交还是手动提交，都不保证提交成功</font>。因为 Kafka broker 可能发生故障或网络延迟，导致<font style="color:rgb(216,57,49);">提交失败或延迟</font>。因此，<font style="background-color:rgba(255,246,122,0.8);">消费者需要处理提交失败或延迟的情况</font>。

+ 提交失败：消费者可以选择重试或放弃。重试的话，可能会导致多次提交同一个 offset 值，但是不会影响正确性，因为 Kafka broker 会忽略重复的 offset 值。放弃的话，可能会导致下次启动时重新消费已经消费过的消息。
+ 提交延迟：消费者可以选择等待或继续。等待的话，可能会导致<font style="background-color:rgba(255,246,122,0.8);">消费速度变慢</font>，或者<font style="background-color:rgba(255,246,122,0.8);">超过会话时间</font>而被认为已经死亡。继续的话，可能会导致下次启动时漏掉一些没有提交成功的消息。

:::

<font style="color:#DF2A3F;">重置 offset</font>

+ 手动重置：可以让消费者精确地控制从哪个位置开始消费。
+ 自动重置：对应三个选项，earliest, latest 和 none。earliest 表示从最早的可用消息开始消费；latest 表示从最新的可用消息开始消费；none 表示如果没有可用的 offset，则抛出异常。

#### （6）消费者组
多个消费者，只要指定了相同的 group_id ，即属于同一个消费者组

<font style="color:rgb(216,57,49);">同一个消费者组内的消费者可以共同消费一个Topic中的数据</font>，

但是一个Topic中是有很多Partition的，消费者是怎么分配 Partition 的呢？

+ 例如有一个Topic，含有一个Partition，有一个消费者组（有消费者A，B），此时消费者A和消费者B中只有一个消费者可以消费到消息，另外一个消费者将不会消费到消息。**这说明当一个消费者组内的消费者数量 > 某 Topic 的 Partition 数量时，多余的消费者是会空闲的**。
+ 例如有一个Topic，含有两个Partition，有一个消费者组（有消费者A，B），此时消费者A和消费者B会分别单独只消费某一个Partition，A和B不会交叉消费不同Partition。**这说明当一个消费者组内的消费者数量 == 某 Topic 的 Partition 数量时，每个消费者对应一个Partition。**<font style="background-color:#81DFE4;">（单播）</font>
+ 例如有一个Topic，含有三个Partition，有一个消费者组（有消费者A，B），此时消费者A和消费者B会有一个消费者消费多个分区。**这说明当一个消费者组内的消费者数量 < 某Topic的Partition数量时，部分消费者会消费多个Partition的消息。****<font style="background-color:#81DFE4;">(多播)</font>**

<font style="background-color:rgba(255,246,122,0.8);">不同消费者组可以共同消费同一个Topic中的数据。</font>

+ 假设有两个消费者组A和B，都订阅了同一个Topic，这时候Topic的某一条消息，消费者组A和消费者组B都可以拉取到。<font style="color:rgb(216,57,49);">即消费者组A会消费一次，消费者组B也会消费一次。</font>消费组内具体的消费逻辑同上单个消费者组组内消费的逻辑。

:::danger 注意
Kafka 采用<font style="color:#DF2A3F;">拉模式</font>消费消息，即消费者主动通过 poll() 向 Broker 请求数据，而不是由 Broker 主动推送。这种设计的好处是消费者可以<font style="color:#DF2A3F;">根据自身处理能力控制拉取频率和批量大小，从而避免被高并发消息压垮</font>，同时提高批量处理效率，是 Kafka 高吞吐架构的重要基础。

:::

