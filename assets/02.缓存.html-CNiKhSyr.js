import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as s,e as n,o as a}from"./app-CoLA7Rat.js";const o={};function r(i,t){return a(),s("div",null,[...t[0]||(t[0]=[n('<ol><li><strong>缓存优化</strong>：使用逻辑过期方案防止 Redis 热点 Key 的缓存击穿问题；使用缓存空值方案解决 Redis Key 的缓存穿透问题；</li><li><strong>数据一致性</strong>：更新数据库后删除缓存，若删除失败消息队列补偿重试，TTL 兜底共同保证数据一致性；</li><li><strong>多级缓存</strong>：使用 Caffeine 本地缓存 和 Redis 缓存搭建二级缓存架构，提高热点数据访问速度，降低 Redis 压力；</li></ol><h2 id="一、缓存击穿" tabindex="-1"><a class="header-anchor" href="#一、缓存击穿"><span>一、缓存击穿</span></a></h2><h3 id="_1-背景阐述" tabindex="-1"><a class="header-anchor" href="#_1-背景阐述"><span>1. 背景阐述</span></a></h3><p><strong>对于平台的准点开放、限时的一些活动信息 或者 热搜榜单，它们是一个热点数据</strong>，在活动上线之前，我们需要提前预热：将其存入 Redis 中进行缓存，目的是提高系统的响应速度，降低数据库的访问压力。</p><h3 id="_2-问题剖析" tabindex="-1"><a class="header-anchor" href="#_2-问题剖析"><span>2. 问题剖析</span></a></h3><p><strong>当把高并发场景的热点数据存入 Redis 缓存</strong>，那么我们需要考虑的问题是：缓存击穿的问题。</p><p>如果缓存的热点数据失效过期的瞬间，有大量的请求访问，那么大量请求将到达数据库，<strong>导致数据库瞬时压力过大甚至可能崩溃</strong>。</p><h3 id="_3-方案构思" tabindex="-1"><a class="header-anchor" href="#_3-方案构思"><span>3. 方案构思</span></a></h3><p>因此需要解决缓存击穿的问题，有两种解决方案：一是使用互斥锁。二是使用逻辑过期。</p><p><strong><strong>互斥锁</strong></strong>：</p><p>当缓存失效时，有大量请求都会去访问数据库，希望获取数据且重新建立缓存再返回给用户数据。<strong>但其实只需要一个请求对应的线程去访问数据库，重新建立起缓存即可</strong>。</p><p>在请求到达缓存后，若缓存不存在，尝试获取互斥锁，大量的请求中，只有一个线程获取锁成功，由这个线程去查询数据库，重新建立缓存，而其他的请求线程获取锁失败，都休眠一小段时间后，不断重试获取缓存数据。</p><p><strong>互斥锁的方案，最终只有一个线程去访问数据库，降低了数据库的访问压力，解决了缓存击穿的问题，但是其他的线程需要等待，性能受到影响，对于外界可能表现出一些不可用或者延迟的现象，但是保证了强一致性。</strong></p><p><strong>而<strong><strong>逻辑过期</strong></strong>的方案是这样的：</strong></p><p>针对热点数据我们<strong>不设置TTL</strong>，也就是说Redis Key永不失效，而是在Redis的Value数据中新增一个属性存储过期时间字段。</p><p>在获取key时需要检查过期时间字段，判断是否过期，如果发现过期，则尝试获取互斥锁，大量的请求中，只有一个线程获取锁成功，由这个线程去开启一个独立线程去查询数据库重建缓存，而其他线程就直接返回Redis中的旧数据。</p><p><strong>这个逻辑过期的方案，最终也是只有一个线程去访问数据库，降低了数据库的访问压力，解决了缓存击穿的问题，并且线程无需等待，性能比较好，保证了服务的可用性，但是部分请求返回了Redis的旧数据，没有保证一致性。</strong></p><p>所以这两个方案的对比，其实就是 <strong>可用性和一致性的抉择 (CAP定理)</strong> ：</p><ul><li>互斥锁保证了一致性，牺牲了可用性；</li><li>逻辑过期保证了可用性，而牺牲了一致性</li></ul><p><strong>针对这个热搜榜单，它其实是一种社交媒体类型的数据，对于一致性的要求不是很高，因此最终为了保证服务的可用性，选择使用逻辑过期的方案来解决缓存击穿问题。</strong></p><p>在测试阶段，(手动修改数据库中的数据，使得Redis和MySQL数据不一致)，然后等到Redis中的数据逻辑上过期后，使用 Jmeter 进行压力测试，在5s内5000个线程并发请求，QPS是1000，查看日志可以发现只有一次查询数据库重建缓存的过程，<strong>证明在高并发的场景下，没有让所有的请求打到数据库，成功使用逻辑过期方案解决缓存击穿问题</strong>。缺点就是在缓存尚未重建完毕时，前面一小部分的请求(大概200ms是缓存重建的耗时)获取到的是旧的Redis数据，后面所有的请求获取到的是正确的数据。</p><h3 id="_4-复盘总结" tabindex="-1"><a class="header-anchor" href="#_4-复盘总结"><span>4. 复盘总结</span></a></h3><p>总的来说，这是在一个存在 热点数据和高并发请求 的场景下， 使用redis缓存并解决缓存击穿问题的一个工作内容。我考虑了常见的两种解决方案，最终<strong>根据应用场景</strong>选择了逻辑过期的方案。</p><h3 id="衍生思考" tabindex="-1"><a class="header-anchor" href="#衍生思考"><span>衍生思考</span></a></h3><h4 id="什么场景才用互斥锁解决呢" tabindex="-1"><a class="header-anchor" href="#什么场景才用互斥锁解决呢"><span><strong>什么场景才用互斥锁解决呢？</strong></span></a></h4><p>我认为是分业务场景的，例如金融类的业务场景，是要求强一致性的，会使用互斥锁方案。</p><h2 id="二、数据一致性" tabindex="-1"><a class="header-anchor" href="#二、数据一致性"><span>二、数据一致性</span></a></h2><p>更新数据库后删除缓存，若删除失败消息队列补偿重试，TTL 兜底共同保证数据一致性；</p><h3 id="_1-背景阐述-1" tabindex="-1"><a class="header-anchor" href="#_1-背景阐述-1"><span>1. 背景阐述</span></a></h3><p>把数据存入Redis缓存</p><h3 id="_2-问题剖析-1" tabindex="-1"><a class="header-anchor" href="#_2-问题剖析-1"><span>2. 问题剖析</span></a></h3><p>MySQL中的数据是会更新的，需要设法保证Redis和MySQL的数据一致性</p><h3 id="_3-方案构思-1" tabindex="-1"><a class="header-anchor" href="#_3-方案构思-1"><span>3. 方案构思</span></a></h3><p>在更新数据库后，再同步删除缓存，若删除缓存失败，则发送一个消息到Kafka中，消息中携带上要删除的key的信息，同时需要启动Kafka消费者，消费者接收到消息后执行缓存删除逻辑。如果删除缓存失败，消息队列的重试机制就可以发挥作用，<strong>梯度重试</strong>的去删除缓存，<strong>尽量保证</strong>数据的<strong>最终一致性</strong>。</p><blockquote><p>梯度重试（Exponential Backoff）是一种用于处理失败的重试机制，它会根据重试的次数逐渐增加重试的间隔时间，避免在短时间内频繁地重复操作，从而减少系统的负载和资源消耗。</p></blockquote><ul><li>删除缓存还是更新缓存？ <ul><li>更新缓存：每次更新数据库都更新缓存，无效写操作较多</li><li>删除缓存：更新数据库时让缓存失效，查询时再更新缓存</li></ul></li></ul><h3 id="_4-复盘总结-1" tabindex="-1"><a class="header-anchor" href="#_4-复盘总结-1"><span>4. 复盘总结</span></a></h3><p>当然保证数据一致性还有很多方案，例如binlog 监听同步，延迟双删，Canal + 异步更新缓存。</p><p>当然上述方法都不能保证MySQL数据和Redis缓存的数据强一致性，只是保证最终一致性</p><p><strong>无论选择哪种方案都需要为缓存设置TTL，作为兜底策略。</strong></p><blockquote><p><strong>&quot;设置过期时间&quot;就像是给缓存加了&quot;自动清理保险&quot;，即使我们主动删除失败，系统也能在一定时间后自我修复，避免永久性的数据不一致。</strong></p></blockquote><h3 id="衍生思考-1" tabindex="-1"><a class="header-anchor" href="#衍生思考-1"><span>衍生思考</span></a></h3><ol><li><h4 id="使用消息队列重试-如果一直失败怎么办" tabindex="-1"><a class="header-anchor" href="#使用消息队列重试-如果一直失败怎么办"><span><strong>使用消息队列重试，如果一直失败怎么办？</strong></span></a></h4></li></ol><p><strong>记录失败次数</strong>，程序里检测达到最大重试次数后，<strong>触发告警，人工介入排查原因</strong></p><ol start="2"><li><h4 id="为什么是先更新mysql-后删除redis缓存" tabindex="-1"><a class="header-anchor" href="#为什么是先更新mysql-后删除redis缓存"><span><strong>为什么是先更新MySQL，后删除Redis缓存？</strong></span></a></h4></li></ol><p>选择“先更新数据库，再删除缓存”，核心考虑是尽量缩短不一致窗口。</p><blockquote><blockquote><blockquote><p>更新DB --&gt; 删缓存，这里数据不一致的时间，就是下一个请求来临时，从数据库调副本到缓存的时间。这个时间，越高并发，是越短的。</p></blockquote></blockquote></blockquote><p>出现数据不一致问题的情况分析如下（两读夹一写）</p><p>a. 读请求：缓存未命中，读取数据库的值为20<br> b. 写请求：更新数据库的值为21，删除缓存<br> c. 读请求：将20写回缓存</p><p><strong>但上述情况出现的概率很小</strong>：因为 更新MySQL的耗时 &gt;&gt; 写入Redis缓存的耗时，正常流程下不应该在经过了写请求之后，读请求才把旧值写回缓存。</p><p>另外，万一数据库出了啥问题更新失败，Redis不删除，数据库和缓存还是一致的，万一缓存删除失败，可以消息队列重试或者设置过期时间兜底，这就是可修复的不一致。</p><blockquote><blockquote><blockquote><p>删缓存 --&gt; 更新DB，这里数据不一致的时间，就是更新mySql的时间+读请求来临同步redis的时间。</p></blockquote></blockquote></blockquote><ol><li><strong>此时出现数据不一致的概率会大很多</strong>，分析如下：</li><li>写请求：删除缓存</li><li>读请求：缓存未命中、读取数据库的值，更新缓存值为20</li><li>写请求：更新数据库的值为21</li></ol><p>因为更新MySQL的耗时 &gt;&gt; 删除Redis缓存的耗时，所以很有可能会有并发读请求在&quot;删除缓存&quot;和&quot;更新数据库&quot; 之间执行，导致数据不一致。</p><p>另外，万一数据库出了啥问题更新失败，那实际上已经没有东西了，但是数据库没减去1，就会导致超卖。</p><table><thead><tr><th>顺序</th><th>不一致窗口</th><th>风险级别</th></tr></thead><tbody><tr><td>先更新DB，再删缓存</td><td>只有“删除失败”才不一致</td><td>低</td></tr><tr><td>先删缓存，再更新DB</td><td>更新期间一定存在风险窗口</td><td>高</td></tr></tbody></table><ol start="3"><li><h4 id="什么是延迟双删" tabindex="-1"><a class="header-anchor" href="#什么是延迟双删"><span><strong>什么是延迟双删</strong></span></a></h4><p>a. 先删除缓存<br> b. 更新数据库<br> c. 延迟一定时间后，删除缓存</p></li></ol><h2 id="三、多级缓存" tabindex="-1"><a class="header-anchor" href="#三、多级缓存"><span>三、多级缓存</span></a></h2><p><strong>多级缓存</strong>：使用 Caffeine 本地缓存 和 Redis 缓存搭建二级缓存架构，提高热点数据访问速度，降低 Redis 压力；</p><h3 id="_1-背景阐述-2" tabindex="-1"><a class="header-anchor" href="#_1-背景阐述-2"><span>1. 背景阐述</span></a></h3><p>对于一些存储在Redis中的过热的key，例如秒杀优惠券的详情页，</p><p>它本身是<strong>更新频率极低的，访问频率很高</strong>的数据。</p><h3 id="_2-问题剖析-2" tabindex="-1"><a class="header-anchor" href="#_2-问题剖析-2"><span>2. 问题剖析</span></a></h3><p>而Redis单实例性能有上限，单个Redis的压力过大，Redis可能成为系统瓶颈</p><h3 id="_3-方案构思-2" tabindex="-1"><a class="header-anchor" href="#_3-方案构思-2"><span>3. 方案构思</span></a></h3><p>考虑使用<strong>Caffeine本地缓存+Redis缓存</strong>，搭建二级缓存，</p><p>本地缓存将<strong>热 Key 的访问压力分散到各个应用实例的内存中，显著降低Redis的访问压力</strong></p><p>搭建二级缓存架构后，用户的请求流程将会是</p><ul><li>先从本地缓存中获取数据，如果本地缓存有数据则返回数据</li><li>否则从Redis缓存中获取数据。如果Redis缓存中有数据则更新本地缓存，然后将数据返回客户端</li><li>如果Redis缓存没有数据则去数据库查询数据，然后更新Redis缓存，接着再更新本地缓存，最后将数据返回给客户端</li></ul><p>当然使用本地缓存，有一个问题是，当后端服务<strong>集群部署</strong>时，如果数据库的数据有更新的情况，本地缓存的数据和数据库的数据会出现<strong>数据不一致窗口</strong>，如果要更新/删除本地缓存的数据，因为是集群部署，就要把所有节点的本地缓存的数据都进行更新/删除，此时这个实现稍微有些复杂，例如发送广播消息，所有实例节点监听广播消息，然后在本地缓存更新/删除。</p><p>但是其实可以使用一种更简单的方法，就是我们可以<strong>给本地缓存设置较短时间的TTL</strong>，这样我们可以不用去管本地缓存的数据更新，而是仅依靠TTL，去不断刷新本地缓存的数据。</p><h3 id="_4-复盘总结-2" tabindex="-1"><a class="header-anchor" href="#_4-复盘总结-2"><span>4. 复盘总结</span></a></h3><p>当因为有热Key，导致Redis实例的压力过高时，为了减少Redis的访问压力，并且这个优惠券的详情页数据是极少去更新的，几乎不变的，因此我使用本地缓存进行优化。</p><h3 id="衍生思考-2" tabindex="-1"><a class="header-anchor" href="#衍生思考-2"><span>衍生思考</span></a></h3><ol><li><h4 id="redis单实例压力过大-为什么不搭建redis集群" tabindex="-1"><a class="header-anchor" href="#redis单实例压力过大-为什么不搭建redis集群"><span><em><strong>Redis单实例压力过大，为什么不搭建Redis集群</strong></em></span></a></h4></li></ol><p>第一考虑成本问题，第二即使搭建了Redis集群，热Key存在于某个Redis实例上，依然会使得单台Redis实例压力过大，除非对该热Key进行分片，分散到不同的Redis实例上，这样实现复杂度又增加了。所以可以选择本地缓存方案，简单。</p><ol start="2"><li><h4 id="分布式缓存" tabindex="-1"><a class="header-anchor" href="#分布式缓存"><span><em><strong>分布式缓存？</strong></em></span></a></h4></li></ol><blockquote><p><strong>本地缓存</strong>：是单台应用服务器维度的缓存，会占用服务器本身存储空间。假设一个分布式系统有5台应用服务器，那么这5台服务器中的缓存内容是<strong>独立且相同</strong>的，彼此不相互影响。本地缓存更多的是用来频繁地读，而非写。数据会随着应用程序的重启而丢失</p><p>优点：本地缓存不需要远程网络请求去操作内存空间，没有额外的性能消耗，所以读取速度快。</p><p>缺点：不能进行大数据量存储；应用程序集群部署时，会存在数据更新问题（数据更新不一致）</p><p><strong>分布式缓存</strong>：一种专门做存储的系统（单台服务器或集群）如Redis。只要向其存储一份数据，那么接入该分布式缓存的所有应用服务器可以获取到相同的内容，保证了数据的一致性。举个例子，淘宝商品库存可以放到Redis中，用户在服务器A下了一单库存减少为99，同步更新到Redis，其他用户在服务器B看到的库存也会变成99。</p></blockquote><ul><li>支持大数据量存储：<strong>分布式缓存是独立部署的进程</strong>，拥有自身独自的内存空间，不需要占用应用程序进程的内存空间，并且还支持横向扩展的集群方式部署，所以可以进行大数据量存储。</li><li>数据不会随着应用程序重启而丢失</li><li>数据集中存储，保证数据的一致性</li><li>数据读写分离，高性能，高可用</li></ul><ol start="3"><li><h4 id="caffeine的实现原理" tabindex="-1"><a class="header-anchor" href="#caffeine的实现原理"><span><em><strong>Caffeine的实现原理？</strong></em></span></a></h4></li></ol><p>**答：**Caffeine在设计上注重提高数据访问速度和并发性能。它使用<code>ConcurrentHashMap</code><strong>作为底层存储，并结合</strong>LRU（最近最少使用）<strong>策略来淘汰过期的缓存数据。为了优化并发性能，Caffeine采用了</strong>分段锁（Segment）<strong>和</strong>桶（Bucket）结构，减少线程竞争。</p><p>Count-Min Sketch 与tiny LRU结合使用，优化缓存项的选择和淘汰。传统的 LRU 算法通常基于最近的访问时间进行缓存淘汰，但 <strong>Count-Min Sketch</strong> 使得算法可以根据 <strong>访问频率</strong> 做出更智能的决策，从而优化缓存的有效性。，从而有效地管理缓存条目，并确保热点数据得到优先保留。在写操作上，它采用类似<strong>WAL</strong>（Write-Ahead Logging）的机制，通过多生产者单消费者模式来缓存写入任务，从而提高并发写入的效率。</p><blockquote><p><strong>WAL</strong> 是一种日志机制，确保数据的变更首先记录到日志文件中，然后才被应用到实际的数据存储中，这样可以保证数据的一致性和恢复。</p><p>在 Caffeine 中，<strong><code>writeBuffer</code></strong> 作为缓存写入的缓冲区，数据先进入这个缓冲区，然后在合适的时机批量刷新到内存缓存中，缓冲区类似于 WAL 的日志记录，确保缓存写入操作的高效性和一致性。</p></blockquote><table><thead><tr><th>特性</th><th>普通LRU</th><th>TinyLRU</th></tr></thead><tbody><tr><td>内存消耗</td><td>较高（使用双向链表 + HashMap）</td><td>较低（优化的内部结构，减少内存开销）</td></tr><tr><td>数据结构</td><td>双向链表 + HashMap</td><td>单向链表+HashMap</td></tr><tr><td>性能</td><td>稍低（由于双向链表维护前后指针）</td><td>较高（简化的数据结构，减少内存管理复杂性）</td></tr><tr><td>适用场景</td><td>内存较充足的环境，功能完整的缓存系统</td><td>内存敏感的高并发场景，资源有限时</td></tr></tbody></table><blockquote><p>Caffeine 选择使用 <strong>单向链表 + HashMap</strong> 作为 <code>TinyLRU</code> 的实现结构，主要是因为它在 <strong>高并发环境下</strong> 提供了 <strong>内存高效</strong> 和 <strong>操作高效</strong> 的优势。相较于 <strong>传统的双向链表</strong>，这种设计的 <strong>内存占用更少</strong>，且对 <strong>LRU 缓存的管理</strong>足够高效，能够在内存和性能之间做出 <strong>更好的平衡</strong>。对于 Caffeine 这样的高性能缓存库来说，减少内存开销并且保证性能是最重要的目标，因此它将 <strong>单向链表</strong> 作为优化方案。</p></blockquote>',85)])])}const g=e(o,[["render",r]]),l=JSON.parse(`{"path":"/projects/dianping/02.%E7%BC%93%E5%AD%98.html","title":"02. 缓存","lang":"en-US","frontmatter":{"title":"02. 缓存","icon":"database","category":["项目","黑马点评"],"tag":["缓存","缓存击穿","数据一致性","多级缓存","caffeine"],"date":"2026-02-15T00:00:00.000Z","article":false,"description":"缓存优化：使用逻辑过期方案防止 Redis 热点 Key 的缓存击穿问题；使用缓存空值方案解决 Redis Key 的缓存穿透问题； 数据一致性：更新数据库后删除缓存，若删除失败消息队列补偿重试，TTL 兜底共同保证数据一致性； 多级缓存：使用 Caffeine 本地缓存 和 Redis 缓存搭建二级缓存架构，提高热点数据访问速度，降低 Redis 压力；","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"WebPage\\",\\"name\\":\\"02. 缓存\\",\\"description\\":\\"缓存优化：使用逻辑过期方案防止 Redis 热点 Key 的缓存击穿问题；使用缓存空值方案解决 Redis Key 的缓存穿透问题； 数据一致性：更新数据库后删除缓存，若删除失败消息队列补偿重试，TTL 兜底共同保证数据一致性； 多级缓存：使用 Caffeine 本地缓存 和 Redis 缓存搭建二级缓存架构，提高热点数据访问速度，降低 Redis 压力；\\"}"],["meta",{"property":"og:url","content":"https://jiwang.online/projects/dianping/02.%E7%BC%93%E5%AD%98.html"}],["meta",{"property":"og:site_name","content":"jiwang's blog"}],["meta",{"property":"og:title","content":"02. 缓存"}],["meta",{"property":"og:description","content":"缓存优化：使用逻辑过期方案防止 Redis 热点 Key 的缓存击穿问题；使用缓存空值方案解决 Redis Key 的缓存穿透问题； 数据一致性：更新数据库后删除缓存，若删除失败消息队列补偿重试，TTL 兜底共同保证数据一致性； 多级缓存：使用 Caffeine 本地缓存 和 Redis 缓存搭建二级缓存架构，提高热点数据访问速度，降低 Redis 压力；"}],["meta",{"property":"og:type","content":"website"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2026-02-15T16:28:27.000Z"}],["meta",{"property":"article:tag","content":"caffeine"}],["meta",{"property":"article:tag","content":"多级缓存"}],["meta",{"property":"article:tag","content":"数据一致性"}],["meta",{"property":"article:tag","content":"缓存击穿"}],["meta",{"property":"article:tag","content":"缓存"}],["meta",{"property":"article:published_time","content":"2026-02-15T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2026-02-15T16:28:27.000Z"}]]},"git":{"createdTime":1771093340000,"updatedTime":1771172907000,"contributors":[{"name":"dongjiwang","username":"dongjiwang","email":"1790921341@qq.com","commits":3,"url":"https://github.com/dongjiwang"}]},"readingTime":{"minutes":13.95,"words":4184},"filePathRelative":"projects/dianping/02.缓存.md","excerpt":"<ol>\\n<li><strong>缓存优化</strong>：使用逻辑过期方案防止 Redis 热点 Key 的缓存击穿问题；使用缓存空值方案解决 Redis Key 的缓存穿透问题；</li>\\n<li><strong>数据一致性</strong>：更新数据库后删除缓存，若删除失败消息队列补偿重试，TTL 兜底共同保证数据一致性；</li>\\n<li><strong>多级缓存</strong>：使用 Caffeine 本地缓存 和 Redis 缓存搭建二级缓存架构，提高热点数据访问速度，降低 Redis 压力；</li>\\n</ol>\\n<h2>一、缓存击穿</h2>\\n<h3>1. 背景阐述</h3>","autoDesc":true}`);export{g as comp,l as data};
